# Microservices Project (MoSIG M2)

Students of the group:  
+ Hajar MAFTAH EL KASSIMY (hajar.maftah-el-kassimy@grenoble-inp.org, Github ID: elkassimyhajar)  
+ Zainab IBRAHIM (zainab.ibrahim@grenoble-inp.org, Github ID: ibrahimzainab)


## Microservices

### Generation of microservices and Deployment to GCP

After creating the microservices with JHipster, we build the docker images and push them to docker hub.  

![Images pushed to Docker Hub](https://github.com/elkassimyhajar/mastering-microservices-submodules/blob/master/pics/docker-hub-images.png)

To deploy the application, we generate kubernetes descriptors via JHipster and create a cluster on GCP.  

```bash
gcloud container clusters create tuto-cluster --zone  europe-west1-b --machine-type e2-highcpu-4
```

![GCP services](https://github.com/elkassimyhajar/mastering-microservices-submodules/blob/master/pics/services-gcp-console.png)


We scale the invoice application by adding an extra instance.


### Local Deployment with KinD (Kubernetes in Docker)

+ Install Go (KinD is written in Go)  
```bash
wget https://golang.org/dl/go1.15.8.linux-amd64.tar.gz && sudo tar -C /usr/local -xzf go1.15.8.linux-amd64.tar.gz && export PATH=$PATH:/usr/local/go/bin
```
+ Install KinD using Go  
```bash
GO111MODULE="on" go get sigs.k8s.io/kind@v0.10.0 && sudo su
export PATH=$PATH:$HOME/go/bin
```
+ Create a cluster
```bash
kind create cluster
```

+ Make docker images available to KinD  

```bash
kind load docker-image gateway
kind load docker-image invoice
kind load docker-image notification
kind load docker-image productorder
```

![KinD](https://github.com/elkassimyhajar/mastering-microservices-submodules/blob/master/pics/kind.png)

We can forward the gateway port to access the application as follows:  

![KinD](https://github.com/elkassimyhajar/mastering-microservices-submodules/blob/master/pics/kind-port-fwd.png)


### Performance Testing with Gatling

To run the Gatling performance tests, we need to install Gatling, run the registry, gateway and the microservice that we want to test. After that, we can run simulations using in our case:   
```bash
gatling.sh -sf $PWD/user-files/simulations/ -rf $PWD/results
```

![Gatling tests](https://github.com/elkassimyhajar/mastering-microservices-submodules/blob/master/pics/gatling-porder.png)

Complete results generated by running the ProductOrder simulations can be found in this [commit](https://github.com/elkassimyhajar/productorder/commit/94aeff7f8f9701957a2b40af41287cb26393ccc8). 

### Service Mesh (Istio)

Using Istio, we implemented a service mesh in our microservices application. We had to recreate the cluster to acquire more powerful nodes (more memory).  
```bash
gcloud container clusters create tuto-cluster --zone  europe-west1-b --machine-type e2-highmem-4
```

![Gatling tests](https://github.com/elkassimyhajar/mastering-microservices-submodules/blob/master/pics/istio-install.png)  

After adding Istio, each pod get an additional container running inside (The istio proxy => sidecar). We can see details by describing a certain pod.  
For example:  
```bash
kubectl describe pods gateway-76654fc98d-89q9h -n store 
```
**The gateway container:**  
![Gatling tests](https://github.com/elkassimyhajar/mastering-microservices-submodules/blob/master/pics/istio-app-cont.png)  
**The proxy container:**  
![Gatling tests](https://github.com/elkassimyhajar/mastering-microservices-submodules/blob/master/pics/istio-proxy-cont.png)

Istio can also be used for monitoring. We experimented with this using the addons offered in the Istio package.
```bash
kubectl apply -f addons/
```
After executing this command, we could see monitoring pods created in the ***istio-system*** namespace.  

![Gatling tests](https://github.com/elkassimyhajar/mastering-microservices-submodules/blob/master/pics/istio-pods-svc.png)

### Monitoring Dashboards

To access monitoring dashboards from Istio, all we needed is to forward ports to access them locally. (Jaeger/Zipkin were a little different)  
```bash
# Open Jaeger dashboard
istioctl dashboard jaeger
# Open Kiali dashboard
kubectl port-forward svc/kiali -n istio-system 20001
```
#### Prometheus
![Gatling tests](https://github.com/elkassimyhajar/mastering-microservices-submodules/blob/master/pics/prometheus-dash.png)  
#### Grafana
![Gatling tests](https://github.com/elkassimyhajar/mastering-microservices-submodules/blob/master/pics/grafana-dash-1.png)  
![Gatling tests](https://github.com/elkassimyhajar/mastering-microservices-submodules/blob/master/pics/grafana-dash-2.png)  
#### Kiali
![Gatling tests](https://github.com/elkassimyhajar/mastering-microservices-submodules/blob/master/pics/kiali-dash.png)  
![Gatling tests](https://github.com/elkassimyhajar/mastering-microservices-submodules/blob/master/pics/kiali-apps.png)  
#### Jaeger
![Gatling tests](https://github.com/elkassimyhajar/mastering-microservices-submodules/blob/master/pics/jaeger-dash-1.png)  
![Gatling tests](https://github.com/elkassimyhajar/mastering-microservices-submodules/blob/master/pics/jaeger-graph-2.png)  

### Asynchronous Communication

We used RabbitMq and Kafka to implement asynchronous communication between microservices but both had issues and bugs related to changes made in (jhipster
versions)[https://www.jhipster.tech/2020/12/21/jhipster-release-7.0.0-beta.0.html]. 

With RabbitMq, files couldn't be generated even after a lot of debugging(changes in the package.json, changing functions **getAngularAppName=>getFrontendAppName**/**getJhipsterConfig=>getAllJhipsterConfig**).  

![RabbitMq](https://github.com/elkassimyhajar/mastering-microservices-submodules/blob/master/pics/rabbitmqError.png)  

With Kafka, new microservices (notification and productorder) supporting asynchronous communication were created but execution generated some errors. Github repos for those microservices are: [notification-kafka](https://github.com/elkassimyhajar/notification-kafka.git) and [productrorder-kafka](https://github.com/elkassimyhajar/productrorder-kafka).  



## Monolith

To start with, we worked with the application as a whole, a monolith. We generated the application with the entities and the RestAPI, and tested the backend, and the frontend, and did the e2e testing. We also added a CI/CD pipeline with Github actions. The application was next successfully deployed locally with docker and monitored using Prometheus and Grafana. Heroku was used for deployment as well. The monolith can be found in this [Github repo](https://github.com/ibrahimzainab/monolith.git).  

We noticed that all these steps took considerable time and the code was huge. For instance, the CI/CD pipeline was executed entirely for every change no matter how small it was. For this reason, we thought about using a multi-repo code versioning for the microservices application. In other words, we used a separate repository for each microservice and a parent repository that represents the whole application by referencing all its components. To implement this, we used github submodules. Each microservice was a submodule referenced in the parent repository.  
This will ensure a separate CI/CD pipeline for each microservice which will only be triggered if the corresponding microservice had changes.

![Github Submodules](https://github.com/elkassimyhajar/mastering-microservices-submodules/blob/master/pics/github.png)  
